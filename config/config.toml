# config/config.toml

# Default LLM configuration (RunPod)
[llm]
api_type = "runpod"
model = "agent-model"
base_url = "https://your-runpod-endpoint.runpod.net"
api_key = "your-runpod-api-key"
max_tokens = 4096
temperature = 0.7
timeout = 120  # Connection timeout in seconds
retry_count = 3  
streaming_supported = true  
endpoint_id = "your-endpoint-id"  

# Vision model configuration (RunPod)
[llm.vision]
api_type = "runpod"
model = "agent-model-vision"
base_url = "https://your-runpod-endpoint.runpod.net"
api_key = "your-runpod-api-key"
max_tokens = 4096
temperature = 0.7

# OpenAI configuration (alternative provider)
[llm.openai]
api_type = "openai"
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "your-openai-api-key"
max_tokens = 4096
temperature = 0.7

# Azure OpenAI configuration (alternative provider)
[llm.azure]
api_type = "azure"
model = "gpt-4"
base_url = "https://your-azure-endpoint.openai.azure.com/openai/deployments/your-deployment-id"
api_key = "your-azure-api-key"
api_version = "2024-02-01"
max_tokens = 4096
temperature = 0.7

# Anthropic configuration (alternative provider)
[llm.anthropic]
api_type = "anthropic"
model = "claude-3-sonnet-20240229"
base_url = "https://api.anthropic.com/v1"
api_key = "your-anthropic-api-key"
max_tokens = 4096
temperature = 0.7

# Browser configuration
[browser]
headless = false
disable_security = true
extra_chromium_args = []
max_content_length = 2000

# Search configuration
[search]
engine = "Google"
fallback_engines = ["DuckDuckGo", "Bing"]
retry_delay = 60
max_retries = 3
lang = "en"
country = "us"

# Sandbox configuration
[sandbox]
use_sandbox = false
image = "python:3.12-slim"
work_dir = "/workspace"
memory_limit = "1g"
cpu_limit = 2.0
timeout = 300
network_enabled = true

# MCP configuration
[mcp]
server_reference = "app.mcp.server"
